{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIbenhLQweSLhZVylSA6eI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SravanPuvvada/algae_sensor_cnn/blob/main/algae_sensor_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/algae_sensor_cnn\n",
        "#!git clone https://github.com/SravanPuvvada/algae_sensor_cnn.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpBChLiyu0d2",
        "outputId": "32fa4766-d8e1-446a-8ff5-e3f57eb804f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'algae_sensor_cnn'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UswAhcq4oNZN",
        "outputId": "fffea40f-a950-4edf-9dfd-a0fa4bd9ec55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'algae_sensor_cnn'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5/5), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SravanPuvvada/algae_sensor_cnn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1xFURtS4THJi",
        "outputId": "f7479463-b424-4cac-9504-f9330500387b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/algae_sensor_cnn\")\n"
      ],
      "metadata": {
        "id": "hpDU5T1QTMIu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbny1jnXyxjT",
        "outputId": "e87d689c-ce5c-4416-bf24-75f101f0d214"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'algae.mat', 'algae_sensor_cnn', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base = \"/content/algae_sensor_cnn\"\n",
        "\n",
        "folders = [\n",
        "    \"src\",\n",
        "    \"data/raw\",\n",
        "    \"data/processed\",\n",
        "    \"notebooks\",\n",
        "    \"results\"\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    os.makedirs(os.path.join(base, f), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VVjhC8Of0rD9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/algae_sensor_cnn\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ix_lXmG0xMr",
        "outputId": "c0c4aed2-a539-4bdf-d2c2-30f52ca1957b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['results',\n",
              " '.gitattributes',\n",
              " 'notebooks',\n",
              " '.git',\n",
              " 'README.md',\n",
              " '.gitignore',\n",
              " 'data',\n",
              " 'src']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open(\"/content/algae_sensor_cnn/src/__init__.py\", \"w\").close()\n"
      ],
      "metadata": {
        "id": "AZv43kLT08u7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/algae_sensor_cnn\")\n"
      ],
      "metadata": {
        "id": "U1G2_WYv0_1K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile /content/algae_sensor_cnn/src/data_loader.py\n",
        "# import scipy.io as sio\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# def load_algae_mat(filepath):\n",
        "#     data = sio.loadmat(filepath)\n",
        "#     if 'algae' not in data:\n",
        "#         raise KeyError(\"Expected 'algae' not found\")\n",
        "#     return data['algae']\n",
        "\n",
        "# def mat_struct_to_dataframe(algae_struct):\n",
        "#     fields = algae_struct.dtype.names\n",
        "#     df_dict = {}\n",
        "\n",
        "#     for field in fields:\n",
        "#         if field == 'comments':\n",
        "#             continue\n",
        "\n",
        "#         entry = algae_struct[field][0, 0]\n",
        "#         if 'data' not in entry.dtype.names:\n",
        "#             continue\n",
        "\n",
        "#         values = np.array(entry['data'][0, 0]).squeeze()\n",
        "#         if values.ndim == 1:\n",
        "#             df_dict[field] = values\n",
        "\n",
        "#     min_len = min(len(v) for v in df_dict.values())\n",
        "#     for k in df_dict:\n",
        "#         df_dict[k] = df_dict[k][:min_len]\n",
        "\n",
        "#     return pd.DataFrame(df_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiSDdAcD1FzL",
        "outputId": "a827fa49-bcbd-402a-9d24-bc8429b904a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/algae_sensor_cnn/src/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/data_loader.py\n",
        "# ===============================\n",
        "# data_loader.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "Load and parse MATLAB (.mat) sensor data into clean pandas DataFrames.\n",
        "Handles nested MATLAB structs safely.\n",
        "\"\"\"\n",
        "\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_algae_mat(filepath: str) -> dict:\n",
        "    \"\"\"\n",
        "    Load algae .mat file and return raw MATLAB struct.\n",
        "    \"\"\"\n",
        "    data = sio.loadmat(filepath)\n",
        "    if 'algae' not in data:\n",
        "        raise KeyError(\"Expected 'algae' variable not found in .mat file\")\n",
        "    return data['algae']\n",
        "\n",
        "\n",
        "def mat_struct_to_dataframe(algae_struct) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert nested MATLAB algae struct into a clean pandas DataFrame.\n",
        "    Each column represents a sensor signal.\n",
        "    \"\"\"\n",
        "    fields = algae_struct.dtype.names\n",
        "    df_dict = {}\n",
        "\n",
        "    for field in fields:\n",
        "        if field == 'comments':\n",
        "            continue\n",
        "\n",
        "        entry = algae_struct[field][0, 0]\n",
        "        if 'data' not in entry.dtype.names:\n",
        "            continue\n",
        "\n",
        "        values = np.array(entry['data'][0, 0]).squeeze()\n",
        "\n",
        "        if values.ndim != 1:\n",
        "            continue\n",
        "\n",
        "        df_dict[field] = values\n",
        "\n",
        "    if not df_dict:\n",
        "        raise ValueError(\"No valid numeric time-series found in MATLAB struct\")\n",
        "\n",
        "    min_len = min(len(v) for v in df_dict.values())\n",
        "    for k in df_dict:\n",
        "        df_dict[k] = df_dict[k][:min_len]\n",
        "\n",
        "    return pd.DataFrame(df_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE3KGSuuEw99",
        "outputId": "9480680e-6911-422c-d25c-5058fda915c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# data_loader.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "Load and parse MATLAB (.mat) sensor data into clean pandas DataFrames.\n",
        "Handles nested MATLAB structs safely.\n",
        "\"\"\"\n",
        "\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_algae_mat(filepath: str) -> dict:\n",
        "    \"\"\"\n",
        "    Load algae .mat file and return raw MATLAB struct.\n",
        "    \"\"\"\n",
        "    data = sio.loadmat(filepath)\n",
        "    if 'algae' not in data:\n",
        "        raise KeyError(\"Expected 'algae' variable not found in .mat file\")\n",
        "    return data['algae']\n",
        "\n",
        "\n",
        "def mat_struct_to_dataframe(algae_struct) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert nested MATLAB algae struct into a clean pandas DataFrame.\n",
        "    Each column represents a sensor signal.\n",
        "    \"\"\"\n",
        "    fields = algae_struct.dtype.names\n",
        "    df_dict = {}\n",
        "\n",
        "    for field in fields:\n",
        "        if field == 'comments':\n",
        "            continue\n",
        "\n",
        "        entry = algae_struct[field][0, 0]\n",
        "        if 'data' not in entry.dtype.names:\n",
        "            continue\n",
        "\n",
        "        values = np.array(entry['data'][0, 0]).squeeze()\n",
        "\n",
        "        if values.ndim != 1:\n",
        "            continue\n",
        "\n",
        "        df_dict[field] = values\n",
        "\n",
        "    if not df_dict:\n",
        "        raise ValueError(\"No valid numeric time-series found in MATLAB struct\")\n",
        "\n",
        "    min_len = min(len(v) for v in df_dict.values())\n",
        "    for k in df_dict:\n",
        "        df_dict[k] = df_dict[k][:min_len]\n",
        "\n",
        "    return pd.DataFrame(df_dict)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# preprocessing.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "Signal preprocessing utilities: scaling, cleaning, validation.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def scale_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Standardize all columns (zero mean, unit variance).\n",
        "    \"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(df.values)\n",
        "    return pd.DataFrame(scaled, columns=df.columns)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# windowing.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "Sliding window generation for CNN/LSTM models.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_sliding_windows(df: pd.DataFrame, window_size: int, step: int = 1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert multivariate time-series DataFrame into sliding windows.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : ndarray of shape (n_windows, window_size, n_features)\n",
        "    \"\"\"\n",
        "    data = df.values\n",
        "    n_samples = data.shape[0]\n",
        "\n",
        "    windows = []\n",
        "    for start in range(0, n_samples - window_size + 1, step):\n",
        "        end = start + window_size\n",
        "        windows.append(data[start:end])\n",
        "\n",
        "    return np.array(windows)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# models.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "CNN model definitions for time-series classification.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "def build_cnn_model(input_shape: tuple) -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Build a 1D CNN for multivariate time-series classification.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# train.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "End-to-end training pipeline.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def train_model(X, y, model, epochs=20, batch_size=16):\n",
        "    \"\"\"\n",
        "    Train CNN model with validation split.\n",
        "    \"\"\"\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "\"\"\"\n",
        "Evaluation utilities for classification models.\n",
        "Includes ROC-AUC, PR-AUC, confusion matrix, and plots.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "roc_auc_score,\n",
        "average_precision_score,\n",
        "confusion_matrix,\n",
        "ConfusionMatrixDisplay,\n",
        "roc_curve,\n",
        "precision_recall_curve\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_classification(model, X, y_true, threshold=0.5):\n",
        "  \"\"\"\n",
        "  Evaluate a binary classification model.\n",
        "\n",
        "\n",
        "  Returns metrics dictionary.\n",
        "  \"\"\"\n",
        "  y_prob = model.predict(X).ravel()\n",
        "  y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "\n",
        "  metrics = {\n",
        "  \"roc_auc\": roc_auc_score(y_true, y_prob),\n",
        "  \"pr_auc\": average_precision_score(y_true, y_prob),\n",
        "  \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
        "  }\n",
        "\n",
        "\n",
        "  return metrics, y_prob, y_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_roc_curve(y_true, y_prob):\n",
        "  fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr)\n",
        "  plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"ROC Curve\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_pr_curve(y_true, y_prob):\n",
        "  precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "  plt.figure()\n",
        "  plt.plot(recall, precision)\n",
        "  plt.xlabel(\"Recall\")\n",
        "  plt.ylabel(\"Precision\")\n",
        "  plt.title(\"Precision-Recall Curve\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion(y_true, y_pred):\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  disp.plot()\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gFnODuPr1MG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "08de1cb0-3b2d-4949-c265-4a824244f1c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4081862904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_dependency_on_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malias_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_list_append\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/context_managers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_data_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnested_structure_coder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"math.reduce_sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reduce_sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m @deprecation.deprecated_args(None,\n\u001b[0m\u001b[1;32m   2117\u001b[0m                              \u001b[0;34m\"keep_dims is deprecated, use keepdims instead\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m                              \"keep_dims\")\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mdeprecated_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated_args'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     \u001b[0marg_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m     deprecated_positions = _get_deprecated_positional_arguments(\n\u001b[1;32m    508\u001b[0m         deprecated_arg_names, arg_spec)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mdirectly\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m   \u001b[0mdecorators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36munwrap\u001b[0;34m(maybe_tf_decorator)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFDecorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0mdecorators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0m_has_tf_decorator_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m       \u001b[0mdecorators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tf_decorator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36m_has_tf_decorator_attr\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_has_tf_decorator_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   \"\"\"Checks if object has _tf_decorator attribute.\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/preprocessing.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "def scale_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Robust scaling with NaN-safe preprocessing.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Force numeric\n",
        "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "    # 2. Interpolate time-series gaps\n",
        "    df = df.interpolate(method=\"linear\", limit_direction=\"both\")\n",
        "\n",
        "    # 3. Fill remaining NaNs (sensor dropouts)\n",
        "    df = df.fillna(df.median())\n",
        "\n",
        "    # 4. Robust scaling (immune to outliers)\n",
        "    scaler = RobustScaler(quantile_range=(5, 95))\n",
        "    scaled = scaler.fit_transform(df.values)\n",
        "\n",
        "    # 5. Clip extreme tails\n",
        "    scaled = np.clip(scaled, -5, 5)\n",
        "\n",
        "    return pd.DataFrame(scaled, columns=df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XCbuB7Lm_4h",
        "outputId": "3e5c2683-42f5-4f4e-8a7f-0732c08d66ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/preprocessing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/windowing.py\n",
        "# ===============================\n",
        "# windowing.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "Sliding window generation for CNN/LSTM models.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def create_sliding_windows(\n",
        "    df: pd.DataFrame,\n",
        "    window_size: int = 50,\n",
        "    stride: int = 1,\n",
        "    target_col: str = \"oxygen\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Create sliding windows for CNN input and corresponding binary labels.\n",
        "\n",
        "    Label rule:\n",
        "    A window is labeled 1 if the mean oxygen value inside the window\n",
        "    is greater than the global oxygen mean, else 0.\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Compute global mean once (IMPORTANT)\n",
        "    global_oxygen_mean = df[target_col].mean()\n",
        "\n",
        "    # Convert dataframe to numpy for faster slicing\n",
        "    data_values = df.values\n",
        "    oxygen_index = df.columns.get_loc(target_col)\n",
        "\n",
        "    for start in range(0, len(df) - window_size + 1, stride):\n",
        "        end = start + window_size\n",
        "\n",
        "        # Input window (all features)\n",
        "        window = data_values[start:end, :]\n",
        "        X.append(window)\n",
        "\n",
        "        # Label from oxygen column (Option B: window average)\n",
        "        window_oxygen_mean = np.mean(data_values[start:end, oxygen_index])\n",
        "        label = int(window_oxygen_mean > global_oxygen_mean)\n",
        "        y.append(label)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQZXupHgwTZQ",
        "outputId": "c41fe79a-ef63-4533-b7dc-5ae2e14c0074"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/windowing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/windowing_multi.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def create_sliding_windows_multi(\n",
        "    df: pd.DataFrame,\n",
        "    window_size: int = 50,\n",
        "    stride: int = 1,\n",
        "    target_cols=(\"oxygen\", \"PAM0\", \"PAM8\", \"PAM16\", \"density\"),\n",
        "    min_votes: int = 2\n",
        "):\n",
        "    X, y = [], []\n",
        "\n",
        "    # ---- Ensure numeric ----\n",
        "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "    # ---- Global means (exclude density trend) ----\n",
        "    global_means = {}\n",
        "    for col in target_cols:\n",
        "        if col != \"density\":\n",
        "            global_means[col] = df[col].mean()\n",
        "\n",
        "    # ---- Column indices ----\n",
        "    values = df.values\n",
        "    col_idx = {col: df.columns.get_loc(col) for col in target_cols}\n",
        "\n",
        "    for start in range(0, len(df) - window_size + 1, stride):\n",
        "        end = start + window_size\n",
        "        window = values[start:end, :]\n",
        "\n",
        "        # ðŸš¨ HARD FILTER â€” skip poisoned windows\n",
        "        if np.isnan(window).any() or np.isinf(window).any():\n",
        "            continue\n",
        "\n",
        "        # ---------- X ----------\n",
        "        X.append(window)\n",
        "\n",
        "        # ---------- Oxygen vote ----------\n",
        "        oxygen_mean = window[:, col_idx[\"oxygen\"]].mean()\n",
        "        oxygen_vote = int(oxygen_mean > global_means[\"oxygen\"])\n",
        "\n",
        "        # ---------- Photosynthesis vote ----------\n",
        "        pam_votes = 0\n",
        "        for pam in (\"PAM0\", \"PAM8\", \"PAM16\"):\n",
        "            pam_mean = window[:, col_idx[pam]].mean()\n",
        "            if pam_mean > global_means[pam]:\n",
        "                pam_votes += 1\n",
        "\n",
        "        photo_vote = int(pam_votes >= 2)\n",
        "\n",
        "        # ---------- Density trend vote ----------\n",
        "        density_start = window[0, col_idx[\"density\"]]\n",
        "        density_end = window[-1, col_idx[\"density\"]]\n",
        "        density_vote = int(density_end > density_start)\n",
        "\n",
        "        # ---------- Final label ----------\n",
        "        health_score = oxygen_vote + photo_vote + density_vote\n",
        "        y.append(int(health_score >= min_votes))\n",
        "\n",
        "    # ---- Convert safely ----\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    y = np.array(y, dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "    return X, y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6NHDbJf460A",
        "outputId": "c123c181-e411-4d7d-d6e7-7563c1682524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/windowing_multi.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/models.py\n",
        "# ===============================\n",
        "# models.py\n",
        "# ===============================\n",
        "\"\"\"\n",
        "CNN model definitions for time-series classification.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn_model(input_shape: tuple) -> tf.keras.Model:\n",
        "  model = models.Sequential([\n",
        "      layers.Input(shape=(30, 16)),\n",
        "\n",
        "      layers.Conv1D(32, kernel_size=3, activation=\"relu\"),\n",
        "      layers.MaxPooling1D(2),\n",
        "\n",
        "      layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
        "      layers.MaxPooling1D(2),\n",
        "\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(64, activation=\"relu\"),\n",
        "      layers.Dropout(0.3),\n",
        "\n",
        "      layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "      metrics=[\n",
        "          tf.keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\"),\n",
        "          tf.keras.metrics.AUC(curve=\"ROC\", name=\"roc_auc\"),\n",
        "          tf.keras.metrics.Recall(name=\"recall_unhealthy\")\n",
        "      ]\n",
        "  )\n",
        "#   call_backs = [\n",
        "#     tf.keras.callbacks.EarlyStopping(\n",
        "#         monitor=\"val_pr_auc\",\n",
        "#         mode=\"max\",\n",
        "#         patience=8,\n",
        "#         restore_best_weights=True\n",
        "#     )\n",
        "# ]\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez7wudRewhda",
        "outputId": "81bcaf2d-0d75-4362-d0ca-ed8d6bede83e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/train.py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def train_model(X, y, model, epochs=20, batch_size=2):\n",
        "  X_train, X_val, y_train, y_val = train_test_split(\n",
        "      X, y,\n",
        "      test_size=0.2,\n",
        "      stratify=y,        # ðŸ”´ THIS FIXES IT\n",
        "      random_state=42\n",
        "  )\n",
        "  history = model.fit(\n",
        "          X_train, y_train,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "      )\n",
        "\n",
        "  print(\"Train:\", np.unique(y_train, return_counts=True))\n",
        "  print(\"Val:\", np.unique(y_val, return_counts=True))\n",
        "  y_prob = model.predict(X_val).ravel()\n",
        "  y_true = y_val.ravel()\n",
        "  print(\"latest\",y_prob , y_true)\n",
        "\n",
        "  return history ,X_val , y_val\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DPCqFoki0hf",
        "outputId": "6a750931-b021-46cc-ba23-c8845d30ad2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/algae_sensor_cnn/src/evaluate.py\n",
        "# ======================================\n",
        "# evaluate.py\n",
        "# ======================================\n",
        "\"\"\"\n",
        "Model evaluation utilities for imbalanced health detection.\n",
        "\n",
        "Design principles:\n",
        "- No threshold optimization on validation data\n",
        "- Prefer threshold-independent metrics\n",
        "- Focus on unhealthy (positive) class detection\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Threshold-independent evaluation\n",
        "# --------------------------------------------------\n",
        "def evaluate_probabilities(y_true, y_prob):\n",
        "    \"\"\"\n",
        "    Computes threshold-independent metrics.\n",
        "\n",
        "    Returns:\n",
        "    - ROC-AUC\n",
        "    - PR-AUC (PRIMARY METRIC)\n",
        "    \"\"\"\n",
        "    y_true = y_true.ravel()\n",
        "    y_prob = y_prob.ravel()\n",
        "\n",
        "    return {\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_prob),\n",
        "        \"pr_auc\": average_precision_score(y_true, y_prob),\n",
        "    }\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Fixed-threshold evaluation (NO optimization)\n",
        "# --------------------------------------------------\n",
        "def confusion_at_fixed_threshold(y_true, y_prob, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluate model at a fixed, pre-declared threshold.\n",
        "\n",
        "    This avoids overfitting caused by threshold tuning.\n",
        "    \"\"\"\n",
        "    y_true = y_true.ravel()\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    return {\n",
        "        \"threshold\": threshold,\n",
        "        \"TP\": int(tp),\n",
        "        \"FP\": int(fp),\n",
        "        \"FN\": int(fn),\n",
        "        \"TN\": int(tn),\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "    }\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Risk-based evaluation (Top-K)\n",
        "# --------------------------------------------------\n",
        "def recall_at_top_k(y_true, y_prob, fraction=0.2):\n",
        "    \"\"\"\n",
        "    Recall when flagging the top-K highest risk windows.\n",
        "\n",
        "    Example:\n",
        "    fraction=0.2 â†’ \"If we investigate top 20% riskiest windows,\n",
        "    how many unhealthy cases do we catch?\"\n",
        "    \"\"\"\n",
        "    y_true = y_true.ravel()\n",
        "    y_prob = y_prob.ravel()\n",
        "\n",
        "    k = max(1, int(len(y_prob) * fraction))\n",
        "    top_idx = np.argsort(y_prob)[-k:]\n",
        "\n",
        "    recall = y_true[top_idx].sum() / max(1, y_true.sum())\n",
        "\n",
        "    return {\n",
        "        \"fraction_flagged\": fraction,\n",
        "        \"recall_at_k\": recall,\n",
        "        \"windows_flagged\": k,\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lK7ZzlXwbjT",
        "outputId": "5ce91b25-249d-4690-b80e-d70d0ed4739f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/algae_sensor_cnn/src/evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmDiZjINwp2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.data_loader import load_algae_mat, mat_struct_to_dataframe\n",
        "print(\"Imports work âœ…\")\n",
        "\n",
        "from src.preprocessing import scale_dataframe\n",
        "print(\"2nd import works âœ…\")\n",
        "\n",
        "from src.windowing import create_sliding_windows\n",
        "print(\"3rd import works âœ…\")\n",
        "\n",
        "\n",
        "from src.models import build_cnn_model\n",
        "print(\"4th import works âœ…\")\n",
        "\n",
        "from src.train import train_model\n",
        "print(\"5th import works âœ…\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm81L96g1lFP",
        "outputId": "36975b88-c13c-45d2-ecd8-6ece2d743f6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports work âœ…\n",
            "2nd import works âœ…\n",
            "3rd import works âœ…\n",
            "4th import works âœ…\n",
            "5th import works âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile /content/algae-sensor-cnn/src/data_loader.py\n",
        "# %%writefile /content/algae-sensor-cnn/src/preprocessing.py\n",
        "# %%writefile /content/algae-sensor-cnn/src/windowing.py\n",
        "# %%writefile /content/algae-sensor-cnn/src/models.py\n",
        "# %%writefile /content/algae-sensor-cnn/src/train.py\n",
        "import numpy as np\n",
        "from src.data_loader import load_algae_mat, mat_struct_to_dataframe\n",
        "from src.preprocessing import scale_dataframe\n",
        "from src.windowing_multi import create_sliding_windows_multi\n",
        "from src.models import build_cnn_model\n",
        "from src.train import train_model\n",
        "\n",
        "\n",
        "algae = load_algae_mat(\"algae.mat\")\n",
        "df = mat_struct_to_dataframe(algae)\n",
        "df_scaled = scale_dataframe(df)\n",
        "\n",
        "X,y = create_sliding_windows_multi(df_scaled, window_size=30)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Unique labels:\", np.unique(y))\n",
        "\n",
        "# Example label (binary health proxy)\n",
        "#y = (df[\"oxygen\"].values[50:] > df[\"oxygen\"].mean()).astype(int)\n",
        "\n",
        "model = build_cnn_model(input_shape=X.shape[1:])\n",
        "history , X_val , y_val = train_model(X, y, model)\n",
        "\n",
        "##########Evaluation###########\n",
        "\n",
        "from src.evaluate import (\n",
        "    evaluate_probabilities,\n",
        "    confusion_at_fixed_threshold,\n",
        "    recall_at_top_k,\n",
        ")\n",
        "\n",
        "# Predict probabilities\n",
        "y_val_prob = model.predict(X_val).ravel()\n",
        "\n",
        "# 1ï¸âƒ£ Threshold-independent metrics\n",
        "metrics = evaluate_probabilities(y_val, y_val_prob)\n",
        "print(\"Threshold-independent metrics:\")\n",
        "print(metrics)\n",
        "\n",
        "# 2ï¸âƒ£ Fixed threshold evaluation (NO tuning)\n",
        "cm_fixed = confusion_at_fixed_threshold(\n",
        "    y_val,\n",
        "    y_val_prob,\n",
        "    threshold=0.5\n",
        ")\n",
        "print(\"\\nFixed-threshold (0.5) metrics:\")\n",
        "print(cm_fixed)\n",
        "\n",
        "# 3ï¸âƒ£ Risk-based evaluation\n",
        "recall_k = recall_at_top_k(\n",
        "    y_val,\n",
        "    y_val_prob,\n",
        "    fraction=0.5\n",
        ")\n",
        "print(\"\\nRecall@Top-K:\")\n",
        "print(recall_k)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nABmWk3R8RN8",
        "outputId": "af4949d8-53f2-4b34-c923-65b363d2bace",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (50, 30, 16)\n",
            "y shape: (50, 1)\n",
            "Unique labels: [0. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â”‚         \u001b[38;5;34m1,568\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚         \u001b[38;5;34m6,208\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m24,640\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,481\u001b[0m (126.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,481</span> (126.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,481\u001b[0m (126.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,481</span> (126.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.7407 - pr_auc: 0.6287 - recall_unhealthy: 0.0653 - roc_auc: 0.4531 - val_loss: 0.6784 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.1429 - val_roc_auc: 1.0000\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6451 - pr_auc: 0.9116 - recall_unhealthy: 0.5858 - roc_auc: 0.8982 - val_loss: 0.6309 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.7143 - val_roc_auc: 1.0000\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6237 - pr_auc: 0.9804 - recall_unhealthy: 0.7974 - roc_auc: 0.9050 - val_loss: 0.5858 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.7143 - val_roc_auc: 1.0000\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5807 - pr_auc: 0.9856 - recall_unhealthy: 0.9475 - roc_auc: 0.9619 - val_loss: 0.5416 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5423 - pr_auc: 0.9985 - recall_unhealthy: 0.9891 - roc_auc: 0.9964 - val_loss: 0.5033 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4553 - pr_auc: 0.9942 - recall_unhealthy: 0.9323 - roc_auc: 0.9339 - val_loss: 0.4638 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4595 - pr_auc: 0.9979 - recall_unhealthy: 0.9858 - roc_auc: 0.9953 - val_loss: 0.4341 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4482 - pr_auc: 0.9481 - recall_unhealthy: 0.8996 - roc_auc: 0.9437 - val_loss: 0.3995 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3915 - pr_auc: 0.9496 - recall_unhealthy: 0.9152 - roc_auc: 0.9464 - val_loss: 0.3650 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3408 - pr_auc: 0.9984 - recall_unhealthy: 0.9878 - roc_auc: 0.9968 - val_loss: 0.3388 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3584 - pr_auc: 0.8970 - recall_unhealthy: 0.8538 - roc_auc: 0.8897 - val_loss: 0.3123 - val_pr_auc: 1.0000 - val_recall_unhealthy: 1.0000 - val_roc_auc: 1.0000\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2976 - pr_auc: 0.9930 - recall_unhealthy: 0.9277 - roc_auc: 0.9792 - val_loss: 0.2900 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3024 - pr_auc: 0.9387 - recall_unhealthy: 0.8639 - roc_auc: 0.9335 - val_loss: 0.2728 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2202 - pr_auc: 0.9933 - recall_unhealthy: 0.9397 - roc_auc: 0.9812 - val_loss: 0.2598 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1688 - pr_auc: 0.9990 - recall_unhealthy: 0.9839 - roc_auc: 0.9024 - val_loss: 0.2480 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2067 - pr_auc: 0.9975 - recall_unhealthy: 0.9195 - roc_auc: 0.9954 - val_loss: 0.2335 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2023 - pr_auc: 0.9941 - recall_unhealthy: 0.9076 - roc_auc: 0.9868 - val_loss: 0.2246 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1796 - pr_auc: 0.9968 - recall_unhealthy: 0.9595 - roc_auc: 0.9441 - val_loss: 0.2204 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1333 - pr_auc: 0.9990 - recall_unhealthy: 0.9885 - roc_auc: 0.9501 - val_loss: 0.2195 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1360 - pr_auc: 0.9524 - recall_unhealthy: 0.9381 - roc_auc: 0.9524 - val_loss: 0.2220 - val_pr_auc: 1.0000 - val_recall_unhealthy: 0.8571 - val_roc_auc: 1.0000\n",
            "Train: (array([0., 1.], dtype=float32), array([13, 27]))\n",
            "Val: (array([0., 1.], dtype=float32), array([3, 7]))\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "latest [0.08644901 0.7160907  0.07008494 0.75264853 0.98779    0.9779022\n",
            " 0.3027663  0.99278283 0.12823257 0.9371584 ] [0. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Threshold-independent metrics:\n",
            "{'roc_auc': np.float64(1.0), 'pr_auc': np.float64(1.0)}\n",
            "\n",
            "Fixed-threshold (0.5) metrics:\n",
            "{'threshold': 0.5, 'TP': 6, 'FP': 0, 'FN': 1, 'TN': 3, 'precision': 1.0, 'recall': 0.8571428571428571, 'f1': 0.9230769230769231}\n",
            "\n",
            "Recall@Top-K:\n",
            "{'fraction_flagged': 0.5, 'recall_at_k': np.float32(0.71428573), 'windows_flagged': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â€œBecause the dataset is small and constructed using overlapping sliding windows, we avoid optimizing decision thresholds on validation data. Instead, we report threshold-independent metrics (PR-AUC, ROC-AUC) and fixed operating-point recall, along with risk-based Recall@K, which better reflects real-world monitoring use cases.â€\n",
        "\n",
        "\n",
        "To avoid optimistic bias due to small sample size and overlapping time windows, we report threshold-independent metrics (PR-AUC, ROC-AUC) and fixed operating-point recall, rather than optimizing decision thresholds on validation data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0z3u-lSTGvqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read ME**"
      ],
      "metadata": {
        "id": "188hga8DK58H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
       
